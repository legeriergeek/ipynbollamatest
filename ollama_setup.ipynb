{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede52867",
   "metadata": {},
   "source": [
    "# Setting Up the Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf27b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install colab-xterm\n",
    "%load_ext colabxterm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0277632",
   "metadata": {},
   "source": [
    "This code installs the `colab-xterm` library and enables the Colab XTerm extension, which allows us to run shell commands directly in our notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8e0a1",
   "metadata": {},
   "source": [
    "## Installing and serving Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4ebed",
   "metadata": {},
   "source": [
    "### Launching Xterm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xterm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc3c4e",
   "metadata": {},
   "source": [
    "This command opens a full-screen terminal window within your Colab notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b789d14",
   "metadata": {},
   "source": [
    "### Installing Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl https://ollama.ai/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512cb5e",
   "metadata": {},
   "source": [
    "This command downloads the installation script from the Ollama website and executes it. The script will handle the installation process automatically, including downloading and installing necessary dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ad484",
   "metadata": {},
   "source": [
    "### Starting the Ollama Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac75c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama serve &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18368c1c",
   "metadata": {},
   "source": [
    "The `&` at the end runs the command in the background, allowing you to continue using your terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a389c53",
   "metadata": {},
   "source": [
    "### Pulling AI Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601316a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama pull mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577940a",
   "metadata": {},
   "source": [
    "This command downloads the Mistral model and makes it available for use with your Ollama server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07763cae",
   "metadata": {},
   "source": [
    "### Verifying the Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama - version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b74c3",
   "metadata": {},
   "source": [
    "This should display the version number of Ollama if the installation was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ddbd2",
   "metadata": {},
   "source": [
    "### Running Ollama Commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama\n",
    "!ollama generate \"Hello, world!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90628dd3",
   "metadata": {},
   "source": [
    "The first command pulls the “llama” model, and the second generates text using that model."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
